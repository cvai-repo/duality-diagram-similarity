{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from plotting_utils import heatmap,annotate_heatmap\n",
    "list_of_tasks = 'autoencoder curvature denoise edge2d edge3d \\\n",
    "keypoint2d keypoint3d colorization \\\n",
    "reshade rgb2depth rgb2mist rgb2sfnorm \\\n",
    "room_layout segment25d segment2d vanishing_point \\\n",
    "segmentsemantic class_1000 class_places inpainting_whole'\n",
    "\n",
    "task_list = 'autoencoder curvature denoise edge2d edge3d \\\n",
    "keypoint2d keypoint3d  \\\n",
    "reshade rgb2depth rgb2mist rgb2sfnorm \\\n",
    "room_layout segment25d segment2d vanishing_point_well_defined \\\n",
    "segmentsemantic_rb class_1000'\n",
    "\n",
    "task_list_refined = 'autoencoder curvature denoise edge2d edge3d \\\n",
    "keypoint2d keypoint3d  \\\n",
    "reshade rgb2depth rgb2mist rgb2sfnorm \\\n",
    "room_layout segment25d segment2d vanishing_point \\\n",
    "semantic_seg class_1000'\n",
    "\n",
    "task_list = task_list.split()\n",
    "task_list_refined = task_list_refined.split()\n",
    "\n",
    "with open('./../all_affinities_tk.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "t_affinity_matrix = np.zeros((len(task_list),len(task_list)))\n",
    "for i,task1 in enumerate(task_list):\n",
    "    for j,task2 in enumerate(task_list):\n",
    "        t_affinity_matrix[i,j] = data[task1+\"__\"+task2]\n",
    "        \n",
    "with open('./../wins_vs_pixels_16k.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "#print(data)\n",
    "#print(data['win_rates']['segmentsemantic_rb'])\n",
    "import numpy as np\n",
    "t_winrate_matrix = np.zeros((len(task_list),len(task_list)))\n",
    "for i,task1 in enumerate(task_list):\n",
    "    for j,task2 in enumerate(task_list):\n",
    "        t_winrate_matrix[i,j] = data[task1+\"__\"+task2]\n",
    "print(t_winrate_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = './../results/DDScomparison_taskonomy/pascal_5000/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "kernel_affinities =  np.load(results_path+'kernels.npy',allow_pickle=True).item()\n",
    "rdm_affinities = np.load(results_path+'rdms.npy',allow_pickle=True).item()\n",
    "\n",
    "corr_value = {}\n",
    "for kernel,kernel_affinity in kernel_affinities.items():\n",
    "    corr_value[kernel] = {}\n",
    "    for f_ablation,f_ablation_affinity in kernel_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_winrate_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] = temp\n",
    "        corr_value[kernel][f_ablation] = corr_value_matrix\n",
    "            \n",
    "\n",
    "for rdm,rdm_affinity in rdm_affinities.items():\n",
    "    corr_value[rdm] = {}\n",
    "    for f_ablation,f_ablation_affinity in rdm_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_winrate_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] =  temp\n",
    "        corr_value[rdm][f_ablation] = corr_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7843198006864169 ['euclidean', 'znorm']\n"
     ]
    }
   ],
   "source": [
    "max_corr = 0\n",
    "mean_corr = {}\n",
    "for dist,corr_dist in corr_value.items():\n",
    "    mean_corr[dist] = {}\n",
    "    for f_ablation,corr_f_ablation in corr_dist.items():\n",
    "        mean_corr[dist][f_ablation] = round(np.mean(corr_f_ablation),3)\n",
    "        if np.mean(corr_f_ablation) > max_corr:\n",
    "            max_corr = np.mean(corr_f_ablation)\n",
    "            max_combo = [dist,f_ablation]\n",
    "print(max_corr,max_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 rbf    lap  linear  pearson  euclidean  cosine\n",
      "None           0.748  0.748   0.442    0.737      0.556   0.718\n",
      "centering      0.748  0.748   0.442    0.703      0.556   0.700\n",
      "znorm          0.783  0.779   0.772    0.769      0.784   0.779\n",
      "group_norm     0.717  0.736   0.740    0.740      0.735   0.740\n",
      "instance_norm  0.751  0.760   0.776    0.776      0.771   0.776\n",
      "layer_norm     0.714  0.739   0.737    0.737      0.733   0.737\n",
      "batch_norm     0.758  0.768   0.550    0.754      0.683   0.751\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfObj = pd.DataFrame(mean_corr)\n",
    "print(dfObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194340578036585 0.6765866545500134\n"
     ]
    }
   ],
   "source": [
    "mean_col = 0\n",
    "mean_row = 0\n",
    "for j,task in enumerate(task_list):\n",
    "    temp_col,_ = spearmanr(t_winrate_matrix[:,j], t_affinity_matrix[:,j])\n",
    "    temp_row,_ = spearmanr(t_winrate_matrix[j,:], t_affinity_matrix[j,:])\n",
    "    mean_col+=temp_col/len(task_list)\n",
    "    mean_row+=temp_row/len(task_list)\n",
    "print(mean_col,mean_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "kernel_affinities =  np.load(results_path+'kernels.npy',allow_pickle=True).item()\n",
    "rdm_affinities = np.load(results_path+'rdms.npy',allow_pickle=True).item()\n",
    "\n",
    "corr_value = {}\n",
    "for kernel,kernel_affinity in kernel_affinities.items():\n",
    "    corr_value[kernel] = {}\n",
    "    for f_ablation,f_ablation_affinity in kernel_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_affinity_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] = temp\n",
    "        corr_value[kernel][f_ablation] = corr_value_matrix\n",
    "            \n",
    "\n",
    "for rdm,rdm_affinity in rdm_affinities.items():\n",
    "    corr_value[rdm] = {}\n",
    "    for f_ablation,f_ablation_affinity in rdm_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_affinity_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] =  temp\n",
    "        corr_value[rdm][f_ablation] = corr_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8167531718569782 ['pearson', 'znorm']\n"
     ]
    }
   ],
   "source": [
    "max_corr = 0\n",
    "mean_corr = {}\n",
    "for dist,corr_dist in corr_value.items():\n",
    "    mean_corr[dist] = {}\n",
    "    for f_ablation,corr_f_ablation in corr_dist.items():\n",
    "        mean_corr[dist][f_ablation] = round(np.mean(corr_f_ablation),3)\n",
    "        if np.mean(corr_f_ablation) > max_corr:\n",
    "            max_corr = np.mean(corr_f_ablation)\n",
    "            max_combo = [dist,f_ablation]\n",
    "print(max_corr,max_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 rbf    lap  linear  pearson  euclidean  cosine\n",
      "None           0.778  0.784   0.455    0.784      0.566   0.762\n",
      "centering      0.778  0.784   0.455    0.748      0.566   0.743\n",
      "znorm          0.809  0.812   0.809    0.817      0.817   0.816\n",
      "group_norm     0.755  0.777   0.787    0.787      0.778   0.787\n",
      "instance_norm  0.784  0.792   0.815    0.814      0.808   0.814\n",
      "layer_norm     0.755  0.779   0.784    0.784      0.777   0.784\n",
      "batch_norm     0.790  0.803   0.562    0.807      0.701   0.796\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfObj = pd.DataFrame(mean_corr)\n",
    "print(dfObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn2brain_fn",
   "language": "python",
   "name": "dnn2brain_fn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
