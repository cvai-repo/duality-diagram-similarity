{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from plotting_utils import heatmap,annotate_heatmap\n",
    "list_of_tasks = 'autoencoder curvature denoise edge2d edge3d \\\n",
    "keypoint2d keypoint3d colorization \\\n",
    "reshade rgb2depth rgb2mist rgb2sfnorm \\\n",
    "room_layout segment25d segment2d vanishing_point \\\n",
    "segmentsemantic class_1000 class_places inpainting_whole'\n",
    "\n",
    "task_list = 'autoencoder curvature denoise edge2d edge3d \\\n",
    "keypoint2d keypoint3d  \\\n",
    "reshade rgb2depth rgb2mist rgb2sfnorm \\\n",
    "room_layout segment25d segment2d vanishing_point_well_defined \\\n",
    "segmentsemantic_rb class_1000'\n",
    "\n",
    "task_list_refined = 'autoencoder curvature denoise edge2d edge3d \\\n",
    "keypoint2d keypoint3d  \\\n",
    "reshade rgb2depth rgb2mist rgb2sfnorm \\\n",
    "room_layout segment25d segment2d vanishing_point \\\n",
    "semantic_seg class_1000'\n",
    "\n",
    "task_list = task_list.split()\n",
    "task_list_refined = task_list_refined.split()\n",
    "\n",
    "with open('./../all_affinities_tk.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "    \n",
    "t_affinity_matrix = np.zeros((len(task_list),len(task_list)))\n",
    "for i,task1 in enumerate(task_list):\n",
    "    for j,task2 in enumerate(task_list):\n",
    "        t_affinity_matrix[i,j] = data[task1+\"__\"+task2]\n",
    "        \n",
    "with open('./../wins_vs_pixels_16k.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "#print(data)\n",
    "#print(data['win_rates']['segmentsemantic_rb'])\n",
    "import numpy as np\n",
    "t_winrate_matrix = np.zeros((len(task_list),len(task_list)))\n",
    "for i,task1 in enumerate(task_list):\n",
    "    for j,task2 in enumerate(task_list):\n",
    "        t_winrate_matrix[i,j] = data[task1+\"__\"+task2]\n",
    "print(t_winrate_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = './../results/DDScomparison_taskonomy/nyuv2/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "kernel_affinities =  np.load(results_path+'kernels.npy',allow_pickle=True).item()\n",
    "rdm_affinities = np.load(results_path+'rdms.npy',allow_pickle=True).item()\n",
    "\n",
    "corr_value = {}\n",
    "for kernel,kernel_affinity in kernel_affinities.items():\n",
    "    corr_value[kernel] = {}\n",
    "    for f_ablation,f_ablation_affinity in kernel_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_winrate_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] = temp\n",
    "        corr_value[kernel][f_ablation] = corr_value_matrix\n",
    "            \n",
    "\n",
    "for rdm,rdm_affinity in rdm_affinities.items():\n",
    "    corr_value[rdm] = {}\n",
    "    for f_ablation,f_ablation_affinity in rdm_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_winrate_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] =  temp\n",
    "        corr_value[rdm][f_ablation] = corr_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8422584604324396 ['linear', 'instance_norm']\n"
     ]
    }
   ],
   "source": [
    "max_corr = 0\n",
    "mean_corr = {}\n",
    "for dist,corr_dist in corr_value.items():\n",
    "    mean_corr[dist] = {}\n",
    "    for f_ablation,corr_f_ablation in corr_dist.items():\n",
    "        mean_corr[dist][f_ablation] = round(np.mean(corr_f_ablation),3)\n",
    "        if np.mean(corr_f_ablation) > max_corr:\n",
    "            max_corr = np.mean(corr_f_ablation)\n",
    "            max_combo = [dist,f_ablation]\n",
    "print(max_corr,max_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 rbf    lap  linear  pearson  euclidean  cosine\n",
      "None           0.784  0.782   0.654    0.806      0.721   0.828\n",
      "centering      0.784  0.782   0.654    0.780      0.721   0.749\n",
      "znorm          0.784  0.807   0.797    0.829      0.798   0.815\n",
      "group_norm     0.821  0.800   0.825    0.825      0.820   0.825\n",
      "instance_norm  0.830  0.835   0.842    0.842      0.839   0.842\n",
      "layer_norm     0.813  0.807   0.806    0.806      0.807   0.806\n",
      "batch_norm     0.792  0.808   0.737    0.833      0.791   0.808\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfObj = pd.DataFrame(mean_corr)\n",
    "print(dfObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9194340578036585 0.6765866545500134\n"
     ]
    }
   ],
   "source": [
    "mean_col = 0\n",
    "mean_row = 0\n",
    "for j,task in enumerate(task_list):\n",
    "    temp_col,_ = spearmanr(t_winrate_matrix[:,j], t_affinity_matrix[:,j])\n",
    "    temp_row,_ = spearmanr(t_winrate_matrix[j,:], t_affinity_matrix[j,:])\n",
    "    mean_col+=temp_col/len(task_list)\n",
    "    mean_row+=temp_row/len(task_list)\n",
    "print(mean_col,mean_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr,pearsonr\n",
    "\n",
    "kernel_affinities =  np.load(results_path+'kernels.npy',allow_pickle=True).item()\n",
    "rdm_affinities = np.load(results_path+'rdms.npy',allow_pickle=True).item()\n",
    "\n",
    "corr_value = {}\n",
    "for kernel,kernel_affinity in kernel_affinities.items():\n",
    "    corr_value[kernel] = {}\n",
    "    for f_ablation,f_ablation_affinity in kernel_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_affinity_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] = temp\n",
    "        corr_value[kernel][f_ablation] = corr_value_matrix\n",
    "            \n",
    "\n",
    "for rdm,rdm_affinity in rdm_affinities.items():\n",
    "    corr_value[rdm] = {}\n",
    "    for f_ablation,f_ablation_affinity in rdm_affinity.items():\n",
    "        corr_value_matrix = np.zeros(len(task_list))\n",
    "        temp_affinity = np.delete(f_ablation_affinity, (7, 18,19), axis=0)\n",
    "        temp_affinity = np.delete(temp_affinity, (7, 18,19), axis=1)\n",
    "        for j,task in enumerate(task_list):\n",
    "            temp,_ = spearmanr(t_affinity_matrix[:,j], temp_affinity[:,j])\n",
    "            corr_value_matrix[j] =  temp\n",
    "        corr_value[rdm][f_ablation] = corr_value_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8640426758938871 ['linear', 'instance_norm']\n"
     ]
    }
   ],
   "source": [
    "max_corr = 0\n",
    "mean_corr = {}\n",
    "for dist,corr_dist in corr_value.items():\n",
    "    mean_corr[dist] = {}\n",
    "    for f_ablation,corr_f_ablation in corr_dist.items():\n",
    "        mean_corr[dist][f_ablation] = round(np.mean(corr_f_ablation),3)\n",
    "        if np.mean(corr_f_ablation) > max_corr:\n",
    "            max_corr = np.mean(corr_f_ablation)\n",
    "            max_combo = [dist,f_ablation]\n",
    "print(max_corr,max_combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 rbf    lap  linear  pearson  euclidean  cosine\n",
      "None           0.799  0.803   0.678    0.840      0.741   0.860\n",
      "centering      0.799  0.803   0.678    0.804      0.741   0.763\n",
      "znorm          0.786  0.817   0.799    0.840      0.802   0.822\n",
      "group_norm     0.855  0.839   0.853    0.853      0.853   0.853\n",
      "instance_norm  0.853  0.857   0.864    0.864      0.863   0.864\n",
      "layer_norm     0.846  0.840   0.840    0.840      0.842   0.840\n",
      "batch_norm     0.796  0.816   0.747    0.849      0.798   0.808\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dfObj = pd.DataFrame(mean_corr)\n",
    "print(dfObj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dnn2brain_fn",
   "language": "python",
   "name": "dnn2brain_fn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
